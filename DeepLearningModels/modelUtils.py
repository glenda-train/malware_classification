import torch
import torch.nn as nn
import torch.nn.functional as F
import utils
import numpy as np
import pandas as pd 

import torchvision
from torch.utils.data import Dataset, DataLoader
from torch.nn.init import kaiming_uniform_
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, roc_curve, auc

import matplotlib.pyplot as plt

class customDataset(Dataset):
    def __init__(self, x_tensor, y_tensor):
        self.x = x_tensor
        self.y = y_tensor
    
    def __getitem__(self, index):
        return (self.x[index], self.y[index])
    
    def __len__(self):
        return len(self.x)

#Loading pre-trained model
def init_weights(m):
    if type(m) == nn.Linear:
        kaiming_uniform_(m.weight, nonlinearity='relu')
        m.bias.data.fill_(0.001)


class MyModel(nn.Module):
    def __init__ (self, input_size, num_classes):
        super().__init__()
        self.input_size = input_size
        self.model = nn.Sequential(
            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3 , stride=1),
            nn.ReLU(),
            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1),
            nn.ReLU(),
            nn.MaxPool1d(3, stride=1),
            nn.Conv1d(in_channels=64, out_channels=256, kernel_size=3, stride=1),
            nn.ReLU(),
            nn.Conv1d(in_channels=256, out_channels=256, kernel_size=3, stride=1),
            nn.ReLU(),
            nn.MaxPool1d(3, stride=1),            
            nn.Flatten(),
            nn.Linear(30208, 2048),
            nn.ReLU(),            
            nn.Linear(2048, 1024),
            nn.ReLU(),        
            nn.Linear(1024, num_classes)
            )
    
    def forward(self, x):
        x = x.unsqueeze(1)
        x = self.model(x)
        
        return x
    
class MyModelLinear(nn.Module):
    def __init__ (self, input_size, num_classes):
        super().__init__()
        self.input_size = input_size
        self.model = nn.Sequential(
            nn.Linear(input_size, 512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Linear(1024, 4096),
            nn.ReLU(),
            nn.Linear(4096, 4096),
            nn.ReLU(),
            nn.Linear(4096, 2048),
            nn.ReLU(),            
            nn.Linear(2048, 1024),
            nn.ReLU(),        
            nn.Linear(1024, num_classes)
            )
    
    def forward(self, x):
        x = self.model(x)
        
        return x
    
def reset_weights(model):
    for layer in model.children():
        if hasattr(layer, 'reset_parameters'):
            print(f'Reset trainable paramenters of layer = {layer}')
            layer.reset_parameters()








