import torch
import torch.nn as nn
import torch.nn.functional as F
import utils
import numpy as np
import pandas as pd 
import seaborn as sns

import torchvision
from torch.utils.data import Dataset, DataLoader, ConcatDataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import KFold
from sklearn.metrics import ConfusionMatrixDisplay, roc_curve, auc, classification_report

from modelUtils import customDataset, MyModelLinear, reset_weights

import matplotlib.pyplot as plt

#Checking device and empting the cache
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
torch.cuda.empty_cache()

#Hyperparameters
in_channel = 1
num_classes = 5
learning_rate = 0.0001
batch_size = 64
num_epochs = 100
k_folds = 5

#Retrieving Dataset with pandas
x = utils.openPDCsv('input.csv')
y = utils.openPDCsv('Label.csv')

#sorting out data into train (0.8) test (0.2)
train_X, test_X, train_y, test_y = train_test_split(x.values,
                                                    y.values, test_size=0.2,
                                                    random_state=33)

#Tensors for train/test
X_train = torch.FloatTensor(train_X).cuda()
X_test = torch.FloatTensor(test_X).cuda()
y_train = torch.LongTensor(train_y).reshape(-1, 1).cuda()
y_test = torch.LongTensor(test_y).reshape(-1, 1).cuda()

input_size = X_train.shape[1]
print(f'Training size:{len(y_train)}')
labels, counts = y_train.unique(return_counts=True)
print(f'Labels: {labels}\nCounts: {counts}')

train_data = customDataset(X_train, y_train)
# train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)

test_data = customDataset(X_test, y_test)
# test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)

dataset = ConcatDataset([train_data, test_data])
#define K-fold cross validator
kfold = KFold(n_splits=k_folds, shuffle=True)

for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):
    print(f'FOLD {fold}')
    
    # Samples, no replacement
    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)
    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)
    
    # Define loareds
    train_loader = DataLoader(dataset=dataset, batch_size=batch_size, sampler=train_subsampler)
    test_loader = DataLoader(dataset=dataset, batch_size=len(test_data), sampler=test_subsampler)

    model = MyModelLinear(input_size, num_classes).cuda()
    model.apply(reset_weights)
    
    criterion = nn.BCEWithLogitsLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    
    
    train_losses = []
    test_losses = []
    train_correct = []
    test_correct = []
    
    for epoch in range(num_epochs):
        trn_corr = 0
        tst_corr = 0
        
        # Training the model
        for b, (x_batch, y_batch) in enumerate(train_loader):
            b+=1
           
            x_batch = x_batch
            y_batch = torch.nn.functional.one_hot(y_batch.flatten(), 5).float()
            
            output = model.forward(x_batch)
            loss = criterion(output, y_batch)
            
            # Tally the number of correct predictions
            predicted = torch.max(output.data, 1)[1]
            corr =  torch.max(y_batch.data, 1)[1]
            batch_corr = (predicted == corr).sum()
            trn_corr += batch_corr
            
            # Update parameters
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            if b%10 == 0:
                print(f'epoch: {epoch:2}  batch: {b:4} [{batch_size*b:6}/{X_train.shape[0]}]  loss: {loss.item():10.8f} accuracy: {trn_corr.item()*100/(batch_size*b):7.3f}%')
            
        train_losses.append(loss)
        train_correct.append(trn_corr)
        
        print(f'Training process has finished')
        
        print(f'Starting testing')
        
        # Evaluating Model
        with torch.no_grad():
            for b, (X_test, y_test) in enumerate(test_loader):
                X_test = X_test
                y_test = torch.nn.functional.one_hot(y_test.flatten(), 5).float()
                
                y_val = model(X_test)
                
                predicted = torch.max(y_val.data, 1)[1]
                corr =  torch.max(y_test.data, 1)[1]
                tst_corr += (predicted == corr).sum()
                    
        loss = criterion(y_val, y_test)
        test_losses.append(loss)
        test_correct.append(tst_corr)
        
    save_path = f"./MyLinearModel/{fold}/MyLinearModel{fold}.pt"
    torch.save({
                'epoch': num_epochs,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': [train_losses, test_losses, loss],
                }, save_path)
    
    # Loss Ploting 
    plt.figure()
    plt.plot(train_losses, label='training loss')
    plt.plot(test_losses, label='validation loss')
    plt.title(f'loss at the end of each epoch for fold {fold}')
    plt.legend();
    
    save_path = f"./MyLinearModel/{fold}/PlotLossEpochs{fold}.png"
    plt.savefig(save_path)
    
    # ROC curve
    y_test_np = y_test.cpu().detach().numpy()
    y_val_np = y_val.cpu().detach().numpy()

    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(num_classes):
        fpr[i], tpr[i], _ = roc_curve(y_test_np[:, i], y_val_np[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    fpr["micro"], tpr["micro"], _ = roc_curve(y_test_np.ravel(), y_val_np.ravel())
    roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

    plt.figure()
    plt.plot(fpr["micro"], tpr["micro"],
             label='micro-average ROC curve (area = {0:0.2f})'
                   ''.format(roc_auc["micro"]))
    for i in range(num_classes):
        plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'
                                       ''.format(i, roc_auc[i]))

    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC curve for fold {fold}')
    plt.legend(loc="lower right")
    
    save_path = f"./MyLinearModel/{fold}/ROCAUC{fold}.png"
    plt.savefig(save_path)
    plt.show()
    
    
    #Confusion matrix
    y_test_cm = torch.max(y_test, 1)[1].cpu()
    plt.figure()
    predicted = predicted.cpu()
    cm = confusion_matrix(predicted.view(-1), y_test_cm.view(-1))
    f = sns.heatmap(cm, annot=True, fmt='d', cmap="Blues")
    f.set(title = f"Confusion matrix for fold {fold}")
    fig = f.get_figure()
    save_path = f"./MyLinearModel/{fold}/CM{fold}.png"
    fig.savefig(save_path) 
    
    report = classification_report(y_test_cm, predicted.view(-1), labels=[0, 1, 2, 3, 4], output_dict=True)
    report_df = pd.DataFrame(report).transpose()

    with open(f"./MyLinearModel/{fold}/classification_report_CSV{fold}.txt",'w') as tf:
        tf.write(report_df.to_csv())
        
    with open(f"./MyLinearModel/{fold}/classification_report_Latex{fold}.txt",'w') as tf:
        tf.write(report_df.to_latex())
    


