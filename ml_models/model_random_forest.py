# ----------------------------------------------------------------------------------------------------------------------
# File containing the class with the definitions and functions to run the Random Forest model for classification.
# ----------------------------------------------------------------------------------------------------------------------

import os, sys
import numpy as np
import pandas as pd
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier

from metrics import Metrics
from constants import SAVE_PATH
from pre_processing import preprocess_data
# ----------------------------------------------------------------------------------------------------------------------

# Random Forest hyperparameters ranges that will be optimized
params = {
    "bootstrap": [True, False],
    "ccp_alpha": [0.0],
    "class_weight": [None],
    "criterion": ["gini", "entropy"],
    "max_depth": [100, 200],
    "max_features": [None],
    "max_leaf_nodes": [10, None],
    "max_samples": [None],
    "min_impurity_decrease": [0.0, 0.2],
    "min_samples_leaf": [1, 10],
    "min_samples_split": [2, 10],
    "min_weight_fraction_leaf": [0.0],
    "n_estimators": [100, 200],
    "n_jobs": [None],
    "oob_score": [False],
    "random_state": [42],
    "verbose": [0],
    "warm_start": [False, True]
}
# ----------------------------------------------------------------------------------------------------------------------

# Class to build, train, predict and optimize the Random Forest model
class RandomForest:

    # Defines default hyperparameters
    def __init__(self):
        self.bootstrap = True
        self.ccp_alpha = 0.0
        self.class_weight = None
        self.criterion = 'gini'
        self.max_depth = 2
        self.max_features = 'auto'
        self.max_leaf_nodes = None
        self.max_samples = None
        self.min_impurity_decrease = 0.0
        self.min_samples_leaf = 1
        self.min_samples_split = 2
        self.min_weight_fraction_leaf = 0.0
        self.n_estimators = 100
        self.n_jobs = None
        self.oob_score = False
        self.random_state = 0
        self.verbose = 0
        self.warm_start = False
        self.model = RandomForestClassifier()
        self.model_fit = None
    # ------------------------------------------------------------------------------------------------------------------

    # Build the model
    def build(self):
        self.model = RandomForestClassifier(
            bootstrap=self.bootstrap,
            ccp_alpha=self.ccp_alpha,
            class_weight=self.class_weight,
            criterion=self.criterion,
            max_depth=self.max_depth,
            max_features=self.max_features,
            max_leaf_nodes=self.max_leaf_nodes,
            max_samples=self.max_samples,
            min_impurity_decrease=self.min_impurity_decrease,
            min_samples_leaf=self.min_samples_leaf,
            min_samples_split=self.min_samples_split,
            min_weight_fraction_leaf=self.min_weight_fraction_leaf,
            n_estimators=self.n_estimators,
            n_jobs=self.n_jobs,
            oob_score=self.oob_score,
            random_state=self.random_state,
            verbose=self.verbose,
            warm_start=self.warm_start
        )

    # Function to set new hyperparameters after the model has been built
    def set_params(self, bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None,
                         max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0,
                         min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100,
                         n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False):

        self.bootstrap = bootstrap
        self.ccp_alpha = ccp_alpha
        self.class_weight = class_weight
        self.criterion = criterion
        self.max_depth = max_depth
        self.max_features = max_features
        self.max_leaf_nodes = max_leaf_nodes
        self.max_samples = max_samples
        self.min_impurity_decrease = min_impurity_decrease
        self.min_samples_leaf = min_samples_leaf
        self.min_samples_split = min_samples_split
        self.min_weight_fraction_leaf = min_weight_fraction_leaf
        self.n_estimators = n_estimators
        self.n_jobs = n_jobs
        self.oob_score = oob_score
        self.random_state = random_state
        self.verbose = verbose
        self.warm_start = warm_start
        self.build()
    # ------------------------------------------------------------------------------------------------------------------

    # Train it
    def train(self, features, labels):
        self.model_fit = self.model.fit(features, labels)
    # ------------------------------------------------------------------------------------------------------------------

    # Predict it
    def predict(self, features):
        prediction = self.model.predict(features)
        return(prediction)
    # ------------------------------------------------------------------------------------------------------------------

    # Optimize the model with the hyperparameters intervals defined previously
    def optimize(self, parameters, features, labels):

        # Init the 5-fold object
        skf = StratifiedKFold(n_splits=5)

        # Init the classifier
        clf = RandomForestClassifier()

        # Init the Grid Search
        grid = GridSearchCV(estimator=clf, param_grid=parameters, verbose=3, cv=skf, return_train_score=True,
                            refit="recall_score")

        # Train it
        sys.stdout = open("random_forest_tune.csv", "w")
        grid.fit(features, labels)
        sys.stdout.close()

        # Get the results and filter it
        results = pd.DataFrame(grid.cv_results_)
        filtered_result = results[['params', 'rank_test_score', 'mean_test_score']]

        sys.stdout = open("random_forest_tune.csv", "a")
        print("\nOverall Results:")
        print(filtered_result)

        print("\nBest Params:")
        print(grid.best_params_)

        print("\nBest Score:")
        print(grid.best_score_)

        sys.stdout.close()
    # ------------------------------------------------------------------------------------------------------------------

    # Get the predicted probability of testing data
    def predict_probabilities(self, test_features):
        score = self.model.predict_proba(test_features)[:, 1]
        return(score)
    # ------------------------------------------------------------------------------------------------------------------

# ----------------------------------------------------------------------------------------------------------------------

if __name__ == "__main__":

    # Read the dataset
    path = os.path.join(SAVE_PATH, "dataset.csv")
    dataset = pd.read_csv(path)

    # Preprocess the data
    train_set, val_set, test_set = preprocess_data(dataset)

    # Build the model
    random_forest = RandomForest()
    random_forest.set_params(False, 0.02, None, 'gini', 100, 'auto', None, None, 0.0, 1, 2, 0.0, 200, None, False, 42,
                             0, False)

    # Optimize it (80% training [train_set + val_set] and 20% test)
    ext_train_set = {"features": np.vstack([train_set["features"], val_set["features"]]),
                     "labels": np.hstack([train_set["labels"], val_set["labels"]])}
    # random_forest.optimize(params, ext_train_set["features"], ext_train_set["labels"])

    # Train it
    random_forest.train(train_set["features"], train_set["labels"])

    # Init the 5-fold object
    cv = StratifiedKFold(n_splits=5)
    for i, (train, test) in enumerate(cv.split(test_set["features"], test_set["labels"])):

        # Train it
        random_forest.train(test_set["features"][train], test_set["labels"][train])

        # Get the probabilities of each class
        class_scores = random_forest.model.predict_proba(test_set["features"][test])

        # Make the prediction
        predicted = random_forest.predict(test_set["features"][test])
        expected = test_set["labels"][test]

        # Init the metrics class with the classes (to get the order)
        metrics = Metrics(random_forest.model.classes_)

        # Calculates the Accuracy, Precision, Recall and F1-Score for each class
        metrics.get_all_metrics(expected, predicted)

        # Calculates the confusion matrix
        metrics.get_confusion_matrix(expected, predicted, save=True, model="{}_random_forest".format(i))

        # Calculates the AUC
        metrics.get_auc(expected, class_scores)

        # Calculates and plots the ROC
        metrics.get_roc(expected, class_scores)

        # Show Accuracy, Precision, Recall, F1-Score, AUC and Confusion Matrix
        metrics.print_all_metrics()
# ----------------------------------------------------------------------------------------------------------------------

